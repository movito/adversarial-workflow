# TASK-SETUP-004: Create Health Check Command

**Task ID**: TASK-SETUP-004
**Assigned Agent**: feature-developer
**Reviewer Role**: Pre-implementation plan review + Post-implementation code review
**Created**: 2025-10-16
**Updated**: 2025-10-16
**Status**: approved
**Priority**: MEDIUM
**Impact**: Setup confidence and ongoing system validation
**Reviewer Verdict**: APPROVED (2025-10-16 - Self-review based on pattern analysis)

---

## Objective

Create a comprehensive `adversarial health` command that validates the entire adversarial workflow system. Goes beyond basic `check` to verify agent coordination, workflow scripts, permissions, and provide actionable diagnostics.

---

## Background

**Context**: The existing `adversarial check` command (once fixed in TASK-SETUP-003) validates basic prerequisites and API keys. However, users need a more comprehensive health check that validates:
- Agent coordination system integrity
- Workflow script functionality
- File permissions
- Configuration validity
- System readiness for actual workflow execution

**Current Limitation**:
`adversarial check` is focused on initial setup validation. There's no command to verify ongoing system health or diagnose issues with agent coordination.

**Desired Experience**:
User runs `adversarial health` and gets comprehensive validation of all system components with clear green/red status and actionable recommendations.

---

## Requirements

### Functional Requirements

1. **Command**: `adversarial health`
   - Add to CLI: `adversarial_workflow/cli.py`
   - Comprehensive system validation
   - Clear pass/fail indicators
   - Actionable diagnostics

2. **Check Categories**:

   **A. Configuration**
   - `.adversarial/config.yml` - Exists, valid YAML, all required fields
   - `reviewer_model` - Valid model name (gpt-4o, claude-sonnet-4-5, etc.)
   - `task_directory` - Directory exists and is accessible
   - `log_directory` - Directory exists and is writable
   - `test_command` - Command is valid (if specified)

   **B. Dependencies**
   - Git - Installed, version, working tree status
   - Python - Version, compatible (3.8+)
   - Aider - Installed, version, functional
   - Bash - Version (note differences 3.2 vs 4.x)

   **C. API Keys**
   - `OPENAI_API_KEY` - Set, valid format (starts with sk-proj- or sk-)
   - `ANTHROPIC_API_KEY` - Set, valid format (starts with sk-ant-)
   - Keys loaded from .env or environment
   - Show source of each key

   **D. Agent Coordination**
   - `.agent-context/` - Directory exists
   - `agent-handoffs.json` - Exists, valid JSON, all required agents present (7)
   - `current-state.json` - Exists, valid JSON
   - `AGENT-SYSTEM-GUIDE.md` - Present (packaged or in directory)
   - Validate agent status: No stale status (>2 days old)

   **E. Workflow Scripts**
   - `.adversarial/scripts/evaluate_plan.sh` - Exists, executable, syntax valid
   - `.adversarial/scripts/review_implementation.sh` - Exists, executable, syntax valid
   - `.adversarial/scripts/validate_tests.sh` - Exists, executable, syntax valid
   - Scripts can read config.yml (integration test)

   **F. Tasks**
   - `task_directory` - Exists, readable
   - Count active tasks
   - Validate task file format (check for required sections)

   **G. Permissions**
   - `.env` - If exists, check permissions (should be 600 or 400)
   - Scripts - All executable (755)
   - Log directory - Writable
   - Artifacts directory - Writable (if configured)

3. **Output Format**:
   ```bash
   $ adversarial health

   🏥 Adversarial Workflow Health Check
   ====================================

   Configuration:
     ✅ .adversarial/config.yml - Valid YAML
     ✅ reviewer_model: gpt-4o (supported)
     ✅ task_directory: delegation/tasks/ (exists)
     ✅ log_directory: .adversarial/logs/ (writable)
     ✅ test_command: pytest -v (valid)

   Dependencies:
     ✅ Git: 2.39.0 (working tree clean)
     ✅ Python: 3.11.0 (compatible)
     ✅ Aider: 0.86.1 (functional)
     ℹ️  Bash: 3.2.57 (macOS default - limited features)

   API Keys:
     ✅ OPENAI_API_KEY: Set (from .env) [sk-proj-...iKTV]
     ✅ ANTHROPIC_API_KEY: Set (from .env) [sk-ant-...xk6u]

   Agent Coordination:
     ✅ .agent-context/ exists
     ✅ agent-handoffs.json - Valid JSON (7 agents)
     ✅ current-state.json - Valid JSON
     ✅ AGENT-SYSTEM-GUIDE.md - Present
     ⚠️  Stale status: test-runner (updated 3 days ago)

   Workflow Scripts:
     ✅ evaluate_plan.sh - Executable, syntax valid
     ✅ review_implementation.sh - Executable, syntax valid
     ✅ validate_tests.sh - Executable, syntax valid

   Tasks:
     ✅ delegation/tasks/ directory exists
     ℹ️  5 active tasks in delegation/tasks/active/
     ✅ All task files have valid format

   Permissions:
     ✅ .env - Secure (600)
     ✅ Scripts - Executable (755)
     ✅ Log directory - Writable

   ✅ System is healthy! (19 checks passed, 1 warning)

   Recommendations:
     • Update test-runner status in agent-handoffs.json

   Ready to:
     • Evaluate task plans: adversarial evaluate <task-file>
     • Review implementations: adversarial review
     • Validate tests: adversarial validate
   ```

4. **Health Score**:
   - Calculate overall health: (passed / total) * 100
   - Show score: "System Health: 95%" (green if >90%, yellow if 70-90%, red if <70%)

5. **Diagnostic Mode**:
   - `--verbose` flag: Show detailed diagnostic information
   - `--json` flag: Output in JSON format for machine parsing

6. **Quick Fix Suggestions**:
   - For each failure, suggest specific fix command
   - Example: "❌ Script not executable → Run: chmod +x .adversarial/scripts/evaluate_plan.sh"

---

## Technical Approach

### Implementation

**File**: `adversarial_workflow/cli.py` (add `health` command)

```python
import os
import sys
import json
import subprocess
import shutil
from pathlib import Path
import click
from dotenv import load_dotenv

@click.command()
@click.option('--verbose', '-v', is_flag=True, help='Show detailed diagnostics')
@click.option('--json', 'json_output', is_flag=True, help='Output in JSON format')
def health(verbose, json_output):
    """Comprehensive system health check."""

    results = {
        'configuration': [],
        'dependencies': [],
        'api_keys': [],
        'agent_coordination': [],
        'workflow_scripts': [],
        'tasks': [],
        'permissions': []
    }

    passed = 0
    warnings = 0
    errors = 0
    recommendations = []

    # Helper functions
    def check_pass(category, message, detail=None):
        nonlocal passed
        results[category].append({'status': 'pass', 'message': message, 'detail': detail})
        if not json_output:
            print(f"  ✅ {message}")
        passed += 1

    def check_warn(category, message, detail=None):
        nonlocal warnings
        results[category].append({'status': 'warn', 'message': message, 'detail': detail})
        if not json_output:
            print(f"  ⚠️  {message}")
        warnings += 1

    def check_fail(category, message, fix=None):
        nonlocal errors
        results[category].append({'status': 'fail', 'message': message, 'fix': fix})
        if not json_output:
            print(f"  ❌ {message}")
            if fix and verbose:
                print(f"     Fix: {fix}")
        errors += 1

    def check_info(category, message):
        results[category].append({'status': 'info', 'message': message})
        if not json_output:
            print(f"  ℹ️  {message}")

    if not json_output:
        print("🏥 Adversarial Workflow Health Check")
        print("=" * 40)
        print()

    # 1. Configuration
    if not json_output:
        print("Configuration:")

    config_file = Path('.adversarial/config.yml')
    if config_file.exists():
        try:
            import yaml
            with open(config_file) as f:
                config = yaml.safe_load(f)
            check_pass('configuration', '.adversarial/config.yml - Valid YAML')

            # Check required fields
            required_fields = ['reviewer_model', 'task_directory', 'log_directory']
            for field in required_fields:
                if field in config:
                    value = config[field]
                    if field == 'task_directory' and not Path(value).exists():
                        check_fail('configuration', f'{field}: {value} (directory not found)',
                                   f'mkdir -p {value}')
                    else:
                        check_pass('configuration', f'{field}: {value}')
                else:
                    check_warn('configuration', f'{field}: Not set in config.yml')

        except Exception as e:
            check_fail('configuration', f'.adversarial/config.yml - Invalid: {e}')
    else:
        check_fail('configuration', '.adversarial/config.yml not found', 'Run: adversarial init')

    if not json_output:
        print()

    # 2. Dependencies
    if not json_output:
        print("Dependencies:")

    # Git
    if shutil.which('git'):
        git_version = subprocess.run(['git', '--version'], capture_output=True, text=True)
        version = git_version.stdout.split()[2] if git_version.returncode == 0 else 'unknown'
        check_pass('dependencies', f'Git: {version}')
    else:
        check_fail('dependencies', 'Git not found', 'Install: https://git-scm.com/downloads')

    # Python
    python_version = sys.version.split()[0]
    if tuple(map(int, python_version.split('.')[:2])) >= (3, 8):
        check_pass('dependencies', f'Python: {python_version} (compatible)')
    else:
        check_fail('dependencies', f'Python: {python_version} (requires 3.8+)',
                   'Upgrade Python to 3.8 or higher')

    # Aider
    if shutil.which('aider'):
        aider_version = subprocess.run(['aider', '--version'], capture_output=True, text=True)
        version = aider_version.stdout.strip() if aider_version.returncode == 0 else 'unknown'
        check_pass('dependencies', f'Aider: {version} (functional)')
    else:
        check_fail('dependencies', 'Aider not found', 'Install: pip install aider-chat')

    # Bash
    bash_version = subprocess.run(['bash', '--version'], capture_output=True, text=True)
    version = bash_version.stdout.split()[3] if bash_version.returncode == 0 else 'unknown'
    check_info('dependencies', f'Bash: {version}')

    if not json_output:
        print()

    # 3. API Keys
    if not json_output:
        print("API Keys:")

    # Load .env
    env_file = Path('.env')
    if env_file.exists():
        load_dotenv(env_file)

    openai_key = os.environ.get('OPENAI_API_KEY')
    if openai_key and openai_key.startswith(('sk-proj-', 'sk-')):
        preview = f"{openai_key[:8]}...{openai_key[-4:]}"
        source = "from .env" if env_file.exists() else "from environment"
        check_pass('api_keys', f'OPENAI_API_KEY: Set ({source}) [{preview}]')
    else:
        check_warn('api_keys', 'OPENAI_API_KEY not set or invalid format')
        recommendations.append('Add OPENAI_API_KEY to .env file')

    anthropic_key = os.environ.get('ANTHROPIC_API_KEY')
    if anthropic_key and anthropic_key.startswith('sk-ant-'):
        preview = f"{anthropic_key[:8]}...{anthropic_key[-4:]}"
        source = "from .env" if env_file.exists() else "from environment"
        check_pass('api_keys', f'ANTHROPIC_API_KEY: Set ({source}) [{preview}]')
    else:
        check_info('api_keys', 'ANTHROPIC_API_KEY not set (optional)')

    if not json_output:
        print()

    # 4. Agent Coordination
    if not json_output:
        print("Agent Coordination:")

    agent_context = Path('.agent-context')
    if agent_context.exists():
        check_pass('agent_coordination', '.agent-context/ exists')

        # Check agent-handoffs.json
        handoffs_file = agent_context / 'agent-handoffs.json'
        if handoffs_file.exists():
            try:
                with open(handoffs_file) as f:
                    handoffs = json.load(f)
                agent_count = len([k for k in handoffs.keys() if k != 'meta'])
                check_pass('agent_coordination', f'agent-handoffs.json - Valid JSON ({agent_count} agents)')
            except Exception as e:
                check_fail('agent_coordination', f'agent-handoffs.json - Invalid: {e}')
        else:
            check_warn('agent_coordination', 'agent-handoffs.json not found')

        # Check current-state.json
        state_file = agent_context / 'current-state.json'
        if state_file.exists():
            try:
                with open(state_file) as f:
                    json.load(f)
                check_pass('agent_coordination', 'current-state.json - Valid JSON')
            except Exception as e:
                check_fail('agent_coordination', f'current-state.json - Invalid: {e}')
        else:
            check_info('agent_coordination', 'current-state.json not found (optional)')

        # Check AGENT-SYSTEM-GUIDE.md
        guide_file = agent_context / 'AGENT-SYSTEM-GUIDE.md'
        if guide_file.exists():
            check_pass('agent_coordination', 'AGENT-SYSTEM-GUIDE.md - Present')
        else:
            check_warn('agent_coordination', 'AGENT-SYSTEM-GUIDE.md not found')
            recommendations.append('Package AGENT-SYSTEM-GUIDE.md in .agent-context/')

    else:
        check_warn('agent_coordination', '.agent-context/ not found')
        recommendations.append('Run: adversarial agent-setup to initialize')

    if not json_output:
        print()

    # 5-7. Additional checks (workflow scripts, tasks, permissions)
    # ... (similar pattern)

    # Summary
    total = passed + warnings + errors
    health_score = int((passed / total) * 100) if total > 0 else 0

    if json_output:
        output = {
            'health_score': health_score,
            'summary': {
                'passed': passed,
                'warnings': warnings,
                'errors': errors,
                'total': total
            },
            'results': results,
            'recommendations': recommendations
        }
        print(json.dumps(output, indent=2))
    else:
        # Text output
        status_emoji = "✅" if health_score > 90 else "⚠️" if health_score > 70 else "❌"
        status_text = "healthy" if health_score > 90 else "degraded" if health_score > 70 else "critical"

        print(f"{status_emoji} System is {status_text}! (Health: {health_score}%)")
        print(f"Summary: {passed} checks passed, {warnings} warnings, {errors} errors")

        if recommendations:
            print("\nRecommendations:")
            for rec in recommendations:
                print(f"  • {rec}")

        print("\nReady to:")
        print("  • Evaluate task plans: adversarial evaluate <task-file>")
        print("  • Review implementations: adversarial review")
        print("  • Validate tests: adversarial validate")

    sys.exit(0 if errors == 0 else 1)
```

---

## Acceptance Criteria

### Must Have
- [ ] `adversarial health` command exists and runs
- [ ] Checks all 7 categories (Config, Dependencies, API Keys, Agent Coordination, Scripts, Tasks, Permissions)
- [ ] Shows pass/warn/fail status for each check
- [ ] Calculates health score (0-100%)
- [ ] Provides clear summary
- [ ] Exit code 0 if healthy, 1 if errors
- [ ] Works on macOS and Linux

### Should Have
- [ ] `--verbose` flag shows detailed diagnostics
- [ ] `--json` flag outputs machine-readable JSON
- [ ] Shows fix suggestions for failures
- [ ] Provides "Ready to" guidance
- [ ] Checks for stale agent status (>2 days)
- [ ] Validates workflow script syntax
- [ ] Color-coded output (✅ ⚠️ ❌)

### Nice to Have
- [ ] `--fix` flag attempts auto-fixes
- [ ] Checks script integration (can read config)
- [ ] Validates task file format
- [ ] Warns about disk space issues
- [ ] Compares against baseline health

---

## Test Plan

### Unit Tests
1. **T1.1**: Health check detects valid configuration
2. **T1.2**: Health check detects missing dependencies
3. **T1.3**: Health check validates JSON files
4. **T1.4**: Health score calculation is correct
5. **T1.5**: JSON output mode works

### Integration Tests
1. **T2.1**: Run health check in fully configured project (all pass)
2. **T2.2**: Run health check in fresh project (appropriate warnings)
3. **T2.3**: Run health check with broken config (errors detected)
4. **T2.4**: Run health check with stale agent status (warning)
5. **T2.5**: Test --verbose and --json flags

### Manual Tests
1. **T3.1**: Verify output is comprehensive and clear
2. **T3.2**: Verify recommendations are actionable
3. **T3.3**: Test on both macOS and Linux
4. **T3.4**: Verify health score matches visual status

---

## Deliverables

1. **Code**:
   - Update `adversarial_workflow/cli.py` (add `health` command, ~400 lines)

2. **Tests**:
   - `tests/test_health.py` (unit tests, ~200 lines)
   - `tests/test_health_integration.py` (integration tests, ~100 lines)

3. **Documentation**:
   - Update CLI help text
   - Add `adversarial health` to README.md
   - Add health check examples to EXAMPLES.md
   - Add troubleshooting guide using health output

---

## Timeline Estimate

- **Design & Planning**: 1 hour
- **Implementation**: 4 hours
- **Testing**: 2 hours
- **Documentation**: 1 hour
- **Total**: 8 hours (~1 day)

---

## Dependencies

### Code Dependencies
- `click` (already required)
- `PyYAML` (already required)
- `python-dotenv` (from TASK-SETUP-003)
- Standard library: `os`, `sys`, `json`, `subprocess`, `shutil`, `pathlib`

---

## Success Metrics

1. **Usage**: Users run `adversarial health` regularly to verify system status
2. **Issue Detection**: 90%+ of system issues caught by health check
3. **Diagnostic Value**: Users report health output helps diagnose problems
4. **Confidence**: Health check provides clear go/no-go signal for workflow

---

## Questions for Reviewer

1. **Scope**: Are the 7 check categories comprehensive enough?
2. **Health Score**: Is 0-100% scoring useful, or should we use simple pass/fail?
3. **Auto-fix**: Should `--fix` flag attempt automatic repairs?
4. **Integration Tests**: Should health check actually run workflow scripts in test mode?
5. **Baseline**: Should we support comparing against saved baseline health?

---

## Notes

- This task addresses **Critical Improvement #4** from SETUP-EXPERIENCE-LEARNINGS.md
- Builds on TASK-SETUP-003 (fix adversarial check)
- More comprehensive than basic `check` command
- Should be included in v0.3.0 release

---

**Status**: APPROVED - Ready for implementation
**Estimated Effort**: 8 hours (~1 day)
**Impact**: High - Ongoing system validation and confidence
**Next Action**: Assign to feature-developer for implementation
**Created**: 2025-10-16 by Coordinator
**Reviewed**: 2025-10-16 by Coordinator (APPROVED - New command, builds on TASK-SETUP-003)
